{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW10: Algorithmic Fairness \n",
    "\n",
    "### Note: to complete most of this homework notions from week 11 slides are needed\n",
    "\n",
    "In this homework you will assess racial bias in the COMPAS algorithm and judges decisions. \n",
    "\n",
    "The data is a collection of 7000 criminal cases in Florida in which COMPAS was used and it contains information about defendants' demographics, criminal history (e.g., juvenile criminal records), court decision and recidivism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings = lambda *a, **kw: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       7214 non-null   int64  \n",
      " 1   name                     7214 non-null   object \n",
      " 2   first                    7214 non-null   object \n",
      " 3   last                     7214 non-null   object \n",
      " 4   compas_screening_date    7214 non-null   object \n",
      " 5   sex                      7214 non-null   object \n",
      " 6   dob                      7214 non-null   object \n",
      " 7   age                      7214 non-null   int64  \n",
      " 8   age_cat                  7214 non-null   object \n",
      " 9   race                     7214 non-null   object \n",
      " 10  juv_fel_count            7214 non-null   int64  \n",
      " 11  decile_score             7214 non-null   int64  \n",
      " 12  juv_misd_count           7214 non-null   int64  \n",
      " 13  juv_other_count          7214 non-null   int64  \n",
      " 14  priors_count             7214 non-null   int64  \n",
      " 15  days_b_screening_arrest  6907 non-null   float64\n",
      " 16  c_jail_in                6907 non-null   object \n",
      " 17  c_jail_out               6907 non-null   object \n",
      " 18  c_case_number            7192 non-null   object \n",
      " 19  c_offense_date           6055 non-null   object \n",
      " 20  c_arrest_date            1137 non-null   object \n",
      " 21  c_days_from_compas       7192 non-null   float64\n",
      " 22  c_charge_degree          7214 non-null   object \n",
      " 23  c_charge_desc            7185 non-null   object \n",
      " 24  is_recid                 7214 non-null   int64  \n",
      " 25  r_case_number            3471 non-null   object \n",
      " 26  r_charge_degree          3471 non-null   object \n",
      " 27  r_days_from_arrest       2316 non-null   float64\n",
      " 28  r_offense_date           3471 non-null   object \n",
      " 29  r_charge_desc            3413 non-null   object \n",
      " 30  r_jail_in                2316 non-null   object \n",
      " 31  r_jail_out               2316 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         7214 non-null   int64  \n",
      " 34  vr_case_number           819 non-null    object \n",
      " 35  vr_charge_degree         819 non-null    object \n",
      " 36  vr_offense_date          819 non-null    object \n",
      " 37  vr_charge_desc           819 non-null    object \n",
      " 38  type_of_assessment       7214 non-null   object \n",
      " 39  decile_score.1           7214 non-null   int64  \n",
      " 40  score_text               7214 non-null   object \n",
      " 41  screening_date           7214 non-null   object \n",
      " 42  v_type_of_assessment     7214 non-null   object \n",
      " 43  v_decile_score           7214 non-null   int64  \n",
      " 44  v_score_text             7214 non-null   object \n",
      " 45  v_screening_date         7214 non-null   object \n",
      " 46  in_custody               6978 non-null   object \n",
      " 47  out_custody              6978 non-null   object \n",
      " 48  priors_count.1           7214 non-null   int64  \n",
      " 49  start                    7214 non-null   int64  \n",
      " 50  end                      7214 non-null   int64  \n",
      " 51  event                    7214 non-null   int64  \n",
      " 52  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_from_recid'] = pd.to_datetime(df['r_offense_date']) - pd.to_datetime(df['c_offense_date'])\n",
    "df['days_from_recid'] = df['days_from_recid'].dt.days\n",
    "df['two_year_recid2'] = (df['days_from_recid']<=730).astype(int)\n",
    "\n",
    "#generate felony charge dummies\n",
    "df['felony'] = (df['c_charge_degree'] == 'F').astype(int)\n",
    "\n",
    "#generate age dummies\n",
    "d = pd.get_dummies(df['age_cat'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df = df.rename(columns={'25 - 45':'age_cat_25 - 45', 'Greater than 45':'age_cat_Greater than 45', 'Less than 25':'age_cat_Less than 25'})\n",
    "\n",
    "#generate ethnicity, race and compas score dummies\n",
    "d = pd.get_dummies(df['race'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df['male'] = (df['sex'] == 'Male').astype(int)\n",
    "d = pd.get_dummies(df['score_text'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df = df.rename(columns={'High':'score_text_high', 'Medium':'score_text_medium', 'Low':'score_text_low'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting outcomes and predictors\n",
    "\n",
    "The *ideal* target variable for the COMPAS algorithm is the presence of a recidivism episode, while for judges is the decision to send the defendant to jail. For the predictors we use some deomgraphic characteristics **excluding race**, criminal hisotry and type of crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4283\n",
       "1    2931\n",
       "Name: jailed, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# judge decision: \"jailed\" = more than one day in jail.\n",
    "df['jail_days'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "df['jailed'] = (df.jail_days.dt.days > 1).astype(int)\n",
    "D = df['jailed']\n",
    "D.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4557\n",
       "1    2657\n",
       "Name: two_year_recid2, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithm outcome\n",
    "Y = df['two_year_recid2'] \n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>felony</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.646798</td>\n",
       "      <td>0.806626</td>\n",
       "      <td>34.817993</td>\n",
       "      <td>0.067230</td>\n",
       "      <td>0.090934</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>3.472415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477998</td>\n",
       "      <td>0.394971</td>\n",
       "      <td>11.888922</td>\n",
       "      <td>0.473972</td>\n",
       "      <td>0.485239</td>\n",
       "      <td>0.501586</td>\n",
       "      <td>4.882538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            felony         male          age  juv_fel_count  juv_misd_count  \\\n",
       "count  7214.000000  7214.000000  7214.000000    7214.000000     7214.000000   \n",
       "mean      0.646798     0.806626    34.817993       0.067230        0.090934   \n",
       "std       0.477998     0.394971    11.888922       0.473972        0.485239   \n",
       "min       0.000000     0.000000    18.000000       0.000000        0.000000   \n",
       "25%       0.000000     1.000000    25.000000       0.000000        0.000000   \n",
       "50%       1.000000     1.000000    31.000000       0.000000        0.000000   \n",
       "75%       1.000000     1.000000    42.000000       0.000000        0.000000   \n",
       "max       1.000000     1.000000    96.000000      20.000000       13.000000   \n",
       "\n",
       "       juv_other_count  priors_count  \n",
       "count      7214.000000   7214.000000  \n",
       "mean          0.109371      3.472415  \n",
       "std           0.501586      4.882538  \n",
       "min           0.000000      0.000000  \n",
       "25%           0.000000      0.000000  \n",
       "50%           0.000000      2.000000  \n",
       "75%           0.000000      5.000000  \n",
       "max          17.000000     38.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictors\n",
    "predictors = ['felony',\n",
    "              'male', 'age', \n",
    "              'juv_fel_count','juv_misd_count', 'juv_other_count', 'priors_count']\n",
    "X = df[predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                377\n",
       "Asian                 32\n",
       "Native American       18\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7214.000000\n",
       "mean        0.659828\n",
       "std         0.473800\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicator variable for non-white\n",
    "NW = (df['race'] != 'Caucasian').astype(int)\n",
    "NW.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Algorithm: Predict Recidivism from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following you will predict recidivism from defendants' features using a nested training/test split so we can get clean test-set predictions for the whole dataset (see the notebook and homework on double machine learning for how to do this - week 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform nested train/test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_a, X_b, Y_a, Y_b, D_a, D_b,NW_a, NW_b = train_test_split(X, Y, D, NW, test_size = 0.5)\n",
    "\n",
    "df_pred = X_a.append(X_b) \n",
    "#TODO train a logit model to predict recidism (Y) from predictors (X).\n",
    "#TODO form clean test-set predictions for recidivism in the full dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_a, Y_a)\n",
    "Y_b_pred = pd.DataFrame(log_reg.predict(X_b), index=X_b.index)\n",
    "log_reg.fit(X_b, Y_b)\n",
    "Y_a_pred = pd.DataFrame(log_reg.predict(X_a), index=X_a.index)\n",
    "Y_pred = Y_a_pred.append(Y_b_pred).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4130,  427],\n",
       "       [2087,  570]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.77      4557\n",
      "           1       0.57      0.21      0.31      2657\n",
      "\n",
      "    accuracy                           0.65      7214\n",
      "   macro avg       0.62      0.56      0.54      7214\n",
      "weighted avg       0.63      0.65      0.60      7214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO show a confusion matrix, compute accuracy, balanced accuracy, and roc_auc\n",
    "#TODO compute ratio of false positives to false negatives\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "display(confusion_matrix(Y, Y_pred))\n",
    "print(classification_report(Y, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare treatment of whites and non-whites for recidivism prediction\n",
    "##### Refer to week 11 for these concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid2</th>\n",
       "      <th>NW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389076</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      two_year_recid2   NW\n",
       "race                      \n",
       "0            0.328036  0.0\n",
       "1            0.389076  1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO Compare base rates for recidivism outcomes of whites and non-whites\n",
    "ydf = pd.DataFrame(Y)\n",
    "ydf[\"NW\"] = NW\n",
    "ydf.groupby(NW).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1552,   97],\n",
       "       [ 698,  107]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.80      1649\n",
      "           1       0.52      0.13      0.21       805\n",
      "\n",
      "    accuracy                           0.68      2454\n",
      "   macro avg       0.61      0.54      0.50      2454\n",
      "weighted avg       0.64      0.68      0.60      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##TODO Produce confusion matrices, classification reports, and ratio of false positives to false negatives, separately for whites and non-whites.\n",
    "\n",
    "display(confusion_matrix(Y[NW==0], Y_pred[NW==0]))\n",
    "print(classification_report(Y[NW==0], Y_pred[NW==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2578,  330],\n",
       "       [1389,  463]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      2908\n",
      "           1       0.58      0.25      0.35      1852\n",
      "\n",
      "    accuracy                           0.64      4760\n",
      "   macro avg       0.62      0.57      0.55      4760\n",
      "weighted avg       0.62      0.64      0.59      4760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(confusion_matrix(Y[NW==1], Y_pred[NW==1]))\n",
    "print(classification_report(Y[NW==1], Y_pred[NW==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What concepts of \"fairness\" (from class) are (approximately) satisfied by this classifier? Explain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Judges' Decisions: Predict Judge Decision from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following you will predict judges' decisions from defendants' features using a nested training/test split as before. In a second model, include Y-hat from previous section as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO train a logit model to predict judge decision (D) from predictors (X). \n",
    "\n",
    "log_reg.fit(X_a, D_a)\n",
    "D_b_pred = pd.DataFrame(log_reg.predict(X_b), index=X_b.index)\n",
    "D_b_proba = pd.DataFrame(log_reg.predict_proba(X_b), index=X_b.index)\n",
    "log_reg.fit(X_b, D_b)\n",
    "D_a_pred = pd.DataFrame(log_reg.predict(X_a), index=X_a.index)\n",
    "D_a_proba = pd.DataFrame(log_reg.predict_proba(X_a), index=X_a.index)\n",
    "D_pred = D_a_pred.append(D_b_pred).sort_index()\n",
    "D_proba = D_a_proba.append(D_b_proba).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO train a logit model to predict judge decision (D) from predictors (X) and predicted recidivism risk (Yhat)\n",
    "#TODO form clean test-set predictions for the decisions in the full dataset\n",
    "\n",
    "X_a_with_Yhat = X_a.copy()\n",
    "X_a_with_Yhat[\"Yhat\"] = Y_a_pred\n",
    "X_b_with_Yhat = X_b.copy()\n",
    "X_b_with_Yhat[\"Yhat\"] = Y_b_pred\n",
    "\n",
    "log_reg.fit(X_a_with_Yhat, D_a)\n",
    "D_b_pred = pd.DataFrame(log_reg.predict(X_b_with_Yhat), index=X_b_with_Yhat.index)\n",
    "D_b_proba_with = pd.DataFrame(log_reg.predict_proba(X_b_with_Yhat), index=X_b_with_Yhat.index)\n",
    "log_reg.fit(X_b_with_Yhat, D_b)\n",
    "D_a_pred = pd.DataFrame(log_reg.predict(X_a_with_Yhat), index=X_a_with_Yhat.index)\n",
    "D_a_proba_with = pd.DataFrame(log_reg.predict_proba(X_a_with_Yhat), index=X_a_with_Yhat.index)\n",
    "D_pred_with = D_a_pred.append(D_b_pred).sort_index()\n",
    "D_proba_with = D_a_proba_with.append(D_b_proba_with).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare treatment of whites and non-whites for recidivism prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def report_inner(true, pred):\n",
    "    conf_matrix = confusion_matrix(true, pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(conf_matrix)\n",
    "    print(\"Classificaton report:\")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\"Ratio of false positives to false negatives:\")\n",
    "    print(conf_matrix[0,1]/conf_matrix[1,0])\n",
    "\n",
    "def report_outer(true, pred, group):\n",
    "    display(Markdown(\"### Overall:\"))\n",
    "    report_inner(true, pred)\n",
    "    display(Markdown(\"### Whites:\"))\n",
    "    report_inner(true[group==0], pred[group==0])\n",
    "    display(Markdown(\"### Non-whites:\"))\n",
    "    report_inner(true[group==1], pred[group==1])\n",
    "\n",
    "def report(true, pred, pred_with):\n",
    "    display(Markdown(\"## Without Yhat:\"))\n",
    "    report_outer(true, pred, NW)\n",
    "    display(Markdown(\"## With Yhat:\"))\n",
    "    report_outer(true, pred_with, NW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Without Yhat:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Overall:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3777,  506],\n",
       "       [2221,  710]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73      4283\n",
      "           1       0.58      0.24      0.34      2931\n",
      "\n",
      "    accuracy                           0.62      7214\n",
      "   macro avg       0.61      0.56      0.54      7214\n",
      "weighted avg       0.61      0.62      0.58      7214\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.22782530391715444\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Whites:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1391,   94],\n",
       "       [ 800,  169]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.76      1485\n",
      "           1       0.64      0.17      0.27       969\n",
      "\n",
      "    accuracy                           0.64      2454\n",
      "   macro avg       0.64      0.56      0.52      2454\n",
      "weighted avg       0.64      0.64      0.57      2454\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.1175\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Non-whites:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2386,  412],\n",
       "       [1421,  541]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.72      2798\n",
      "           1       0.57      0.28      0.37      1962\n",
      "\n",
      "    accuracy                           0.61      4760\n",
      "   macro avg       0.60      0.56      0.55      4760\n",
      "weighted avg       0.60      0.61      0.58      4760\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.28993666432090076\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## With Yhat:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Overall:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3766,  517],\n",
       "       [2200,  731]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73      4283\n",
      "           1       0.59      0.25      0.35      2931\n",
      "\n",
      "    accuracy                           0.62      7214\n",
      "   macro avg       0.61      0.56      0.54      7214\n",
      "weighted avg       0.61      0.62      0.58      7214\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.235\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Whites:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1381,  104],\n",
       "       [ 785,  184]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76      1485\n",
      "           1       0.64      0.19      0.29       969\n",
      "\n",
      "    accuracy                           0.64      2454\n",
      "   macro avg       0.64      0.56      0.52      2454\n",
      "weighted avg       0.64      0.64      0.57      2454\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.13248407643312102\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Non-whites:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2385,  413],\n",
       "       [1415,  547]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.72      2798\n",
      "           1       0.57      0.28      0.37      1962\n",
      "\n",
      "    accuracy                           0.62      4760\n",
      "   macro avg       0.60      0.57      0.55      4760\n",
      "weighted avg       0.60      0.62      0.58      4760\n",
      "\n",
      "Ratio of false positives to false negatives:\n",
      "0.2918727915194346\n"
     ]
    }
   ],
   "source": [
    "##TODO Produce confusion matrices, classification reports, and ratio of false positives to false negatives, \n",
    "##TODO separately for whites and non-whites, and with/without including Y-hat as a predictor.\n",
    "\n",
    "report(D, D_pred, D_pred_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforcing Statistical Parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will find the the group-specific thresholds for both models of judges' decision (with/without Yhat) that obtain statistical parity.\n",
    "\n",
    "You can use a custom classifier `threshold` for the decision with this type of code snippet: `decisions = (logit.predict_proba(X) >= threshold).astype(int)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model without Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632916</td>\n",
       "      <td>0.367084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.615072</td>\n",
       "      <td>0.384928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531688</td>\n",
       "      <td>0.468312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558269</td>\n",
       "      <td>0.441731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.578280</td>\n",
       "      <td>0.421720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>0.604953</td>\n",
       "      <td>0.395047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>0.609397</td>\n",
       "      <td>0.390603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>0.615436</td>\n",
       "      <td>0.384564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>0.704034</td>\n",
       "      <td>0.295966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>0.634510</td>\n",
       "      <td>0.365490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     0.632916  0.367084\n",
       "1     0.615072  0.384928\n",
       "2     0.531688  0.468312\n",
       "3     0.558269  0.441731\n",
       "4     0.578280  0.421720\n",
       "...        ...       ...\n",
       "7209  0.604953  0.395047\n",
       "7210  0.609397  0.390603\n",
       "7211  0.615436  0.384564\n",
       "7212  0.704034  0.295966\n",
       "7213  0.634510  0.365490\n",
       "\n",
       "[7214 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.367084\n",
       "1       0.384928\n",
       "2       0.468312\n",
       "3       0.441731\n",
       "4       0.421720\n",
       "          ...   \n",
       "7209    0.395047\n",
       "7210    0.390603\n",
       "7211    0.384564\n",
       "7212    0.295966\n",
       "7213    0.365490\n",
       "Name: 1, Length: 7214, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_proba[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.083914\n",
      "         Iterations: 6\n",
      "         Function evaluations: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 0.00025   , -0.00025   ],\n",
       "       [ 0.0001875 , -0.00025   ],\n",
       "       [ 0.00023437, -0.00028125]]), array([0.08391376, 0.08391376, 0.08391376]))\n",
       "           fun: 0.0839137611034634\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 16\n",
       "           nit: 6\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 0.00025, -0.00025])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Find the largest and lowest thresholds to enforce statistical parity\n",
    "##hint: build a recursive function to find the probability threshold that minimizes \n",
    "## the difference between the predicted outcomes for whites and non whites\n",
    "from scipy.optimize import minimize\n",
    "threshold, diff = 0, 1\n",
    "\n",
    "logistic = lambda x: 1/(1+np.exp(-x))\n",
    "def difference(df, threshold):\n",
    "    return (df[NW==1] >= logistic(threshold[0])).astype(int).mean() - (df[NW==0] >= logistic(threshold[1])).astype(int).mean()\n",
    "\n",
    "def find_thresholds(df, threshold):\n",
    "    return minimize(lambda x: difference(df, x), threshold, method='Nelder-Mead', options={'disp': True})\n",
    "\n",
    "find_thresholds(D_proba_with[1], [0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5000624999996744, 0.4999375000003255]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[logistic(x) for x in [0.00025, -0.00025]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092828\n",
      "         Iterations: 5\n",
      "         Function evaluations: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 2.5000e-04,  0.0000e+00],\n",
       "       [ 2.5000e-04, -6.2500e-05],\n",
       "       [ 2.8125e-04, -4.6875e-05]]), array([0.09282804, 0.09282804, 0.09282804]))\n",
       "           fun: 0.09282803585982072\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 14\n",
       "           nit: 5\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.00025, 0.     ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_thresholds(D_proba[1], [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5000624999996744, 0.5]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[logistic(x) for x in [0.00025, 0.     ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 1: More Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains error rate balance (equality of recalls for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains predictive parity (equality of precisions for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains treatment equality (ratio of false positives to false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 2: Pre-Processing for Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress all predictors in `X` on the protected attribute `A` and produce residuals `Xtilde`. Re-do the prediction task above (predicting judges' decision) and discuss how it changes the fairness metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('brj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5853e20241d3d666e40b28ebda8be611448fd3759cbfadd5d542a61bed24d48c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
